# Research-Methods-and-Professional-Practice
# E - Portfolio
## About me 
I am a Masters student pursuing Data science based in the UAE.


## Skills 
- Data Anlysis
- Business analytics
- Data Visualization
- Machine Learning Algorithms
- Deep Learning

## Expertise 
Python, R, Google Analytics 4, Tableau, power BI, Jira, SQLplus , MySQL, SAP 

## Projects
Here are all the tasks of the unit Research Methods and Professional Practice so far!

### Introduction 
This unit gave me the chance to really understand how research fits into the world of data science and not just as a process, but as a way of thinking. As I worked through different topics like building research questions, analysing data, and considering ethical issues, I started to see research as something much more than theory. The tasks we did—like case studies, reflections, and proposal writing—helped me link ideas to real practice. I now view research as a practical tool for asking better questions, making informed decisions, and being more accountable in how I work with data, especially when the outcomes affect people in the real world.

### How I’ve applied these concepts in practice
The activities paired with self reflection really made me aware of where I stood in terms of my personal development.

### Unit 1
#### Reflective Activity 1 – Ethics in Computing in the age of Generative AI
Since the end of 2022, it feels like AI especially generative AI has gone from something we occasionally read about to something we interact with almost daily. Chatbots, image generators, AI-assisted coding and it has all become very normal and very fast. At first, I was impressed but the more I looked at how it is being used, the more I realised there are real gaps in how we are handling the responsibility side of things. As a Data Science student, this realisation hit me harder than I expected. It made me question not only where AI is heading but what role people like me will play in shaping that future.
Reading Correa et al. (2023) helped me see the big picture. Their review of 200 different AI ethics documents from around the world shows how much work is going into defining what “ethical AI” actually means. The surprising part was that there as a lot of overlap in the values and things like transparency, fairness, and accountability come up all the time. But the interpretation of those values varies wildly. Some countries or institutions define transparency as open-source code. Others see it as explainable decisions. Some barely define it at all.
That kind of inconsistency might not seem like a big deal at first but it has consequences. Without shared definitions, we end up with policies that sound responsible on the surface but don’t always lead to meaningful action. Correa and colleagues point this out clearly. Many of these documents are more about signalling than substance. They offer broad ethical goals but few come with clear tools or standards for implementation.
At the same time, Deckard (2023) offers a more grounded view of AI ethics. The way he writes about it is more practical focused on the everyday decisions developers and teams must make. What stood out most to me was his emphasis that ethics is not a box you tick once at the beginning of a project. It is an ongoing responsibility. You do not just write a fairness statement and move on. You keep asking questions even when it is inconvenient.
The challenge is that, as Correa et al. (2023) makes it clear that there is no global roadmap for AI governance. Countries are doing their own thing and in many cases the rules are vague or still being written. That means computing professionals are often left to fill in the ethical blanks themselves. But the hopeful part is that we are not starting from scratch. We have guidance even if it is a bit fragmented. And more importantly, we have the ability to shape what ethical practice looks like in our own environments.
In order to do that three things come in my mind.
First, we need clarity on what ethical terms mean in practice. Words like “transparency” or “harm reduction” should come with examples, case studies, and tools and not just buzzwords. I am not saying every country needs to agree on every detail. But there needs to be enough common ground that we are not reinventing the wheel or talking past each other.
Second, ethics should be part of the design and development process, not something tagged on at the end. Deckard (2023) is clear about this: ethical questions should be asked during system development and not just when things go wrong. That might mean setting up review checkpoints or having cross disciplinary teams look at unintended consequences. It is about creating room to pause and think even when the pressure to launch quickly is high.
Third, we need to reframe what professional responsibility looks like in computing. It is not just about writing clean, functional code. It is about owning the impact of that code, even after it is deployed. It means moving away from the idea that “ethics is someone else’s job.” As a student, I used to assume that too surely there is a legal team or a compliance officer who handles the hard stuff. But now I realised, those decisions often start earlier with the design choices we make as developers.
I also think it is important to be honest and being ethical is not always easy. It can feel awkward to question your team’s approach or point out a problem others have not noticed. But as Deckard (2023) suggests, ethics is not about perfection. It is about showing up, staying curious, and being willing to change course when needed.

In conclusion, AI governance is not just about law or policy it is about people. And while international frameworks like those reviewed by Correa et al. (2023) are essential they only go so far without everyday professionals putting those values into practice. Ethics does not happen in strategy documents. It happens in meetings and code reviews.
Going forward, I do not think we need one universal AI rulebook. But we do need common reference points, clearer definitions, and a stronger culture of responsibility within the computing field.

References
Correa, N., Soler, C., Presno, M.J. and Esponda, I., 2023. Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance.
Deckard, R., 2023. What are Ethics in AI. British Computer Society. Available at: https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/ 


#### Collaborative Learning Discussion 1
The 'Abusive Workplace Behavior' case sheds light on the significant impact toxic leadership can have on both team morale and individual well being. Diane was recruited for her impressive academic track record but quickly became the target of Max who was the team’s technical lead. After a minor coding mistake, Max's response which was shouting at Diane and excluding her from a crucial public demo was harsh but it also fits a troubling pattern. Women on the team have been subjected to similar treatment including having their names removed from journal submissions as a form of punishment.
When Diane approached her manager for support she was met with indifference and was told to “grow up.”. Jean's dismissal of the situation not only undermines Diane’s concerns but also perpetuates a work culture where abusive behavior is tolerated. This violates multiple key principles in the ACM Code of Ethics such as 1.1 (human well-being) and 1.4 (non-discrimination) (ACM, 2018). Jean’s failure to act reflects poorly on leadership and shows a lack of accountability and violates the principles 3.3 and 3.4, which highlights the importance of supporting ethical environments and addressing workplace concerns. Similarly, the BCS Code of Conduct underscores the need for integrity, professionalism, and safeguarding team members, all of which are neglected in this case (BCS, 2015).
This case serves as a powerful reminder that leadership must go beyond technical ability.

References:
ACM (2018). Abusive Workplace Behavior. https://www.acm.org/code-of-ethics/case-studies/abusive-workplace-behavior
BCS (2015). BCS Code of Conduct. https://www.bcs.org/membership/become-a-member/bcs-code-of-conduct/
